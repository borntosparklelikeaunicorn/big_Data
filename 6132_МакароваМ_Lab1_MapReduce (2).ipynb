{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF\n",
        "Алгоритм вычисления TF-IDF для корпуса из восьми документов"
      ],
      "metadata": {
        "id": "-bndC6XlrEu7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "2dCOA2kyXMj_"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, namedtuple, deque\n",
        "import math\n",
        "from typing import List, Tuple, Iterator, NamedTuple\n",
        "from itertools import groupby\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text: str) -> str:\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "def flatten(nested_iterable):\n",
        "    for iterable in nested_iterable:\n",
        "        for element in iterable:\n",
        "            yield element\n",
        "\n",
        "def groupbykey(iterable):\n",
        "    t = {}\n",
        "    for (k2, v2) in iterable:\n",
        "        t[k2] = t.get(k2, []) + [v2]\n",
        "    return t.items()\n",
        "\n",
        "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
        "  return flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(list(map(lambda x: MAP(*x), RECORDREADER))))))"
      ],
      "metadata": {
        "id": "DXr0d52Ic0Ao"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Job 1: Рассчитываем TF (Term Frequency)\n",
        "def RECORDREADER_JOB1():\n",
        "    for docname, contents in documents.items():\n",
        "        yield (docname, contents.split())  #(ID документа, список слов)\n",
        "\n",
        "def MAP_JOB1(docname: str, words: list):\n",
        "    word_count = defaultdict(int)\n",
        "    total_words = len(words)\n",
        "\n",
        "    for word in words:\n",
        "        word_count[word] += 1\n",
        "\n",
        "    for word, count in word_count.items():\n",
        "        yield ((word, docname), count / total_words)  #((Слово, ID документа), TF)\n",
        "\n",
        "def REDUCE_JOB1(term_doc_pair, tf_values):\n",
        "    total_tf = sum(tf_values)\n",
        "    yield (term_doc_pair, total_tf)  #((Слово, ID документа), TF)\n",
        "\n",
        "# Job 2: Рассчитываем DF (Document Frequency)\n",
        "def RECORDREADER_JOB2():\n",
        "    for term_doc_pair, tf in job1_output:\n",
        "        term, doc_id = term_doc_pair\n",
        "        yield (term, (doc_id, tf))\n",
        "\n",
        "def MAP_JOB2(term, doc_tf_pair):\n",
        "    doc_id, tf = doc_tf_pair\n",
        "    yield (term, (doc_id, tf, 1))  #(Слово, (ID документа, TF, 1 для DF))\n",
        "\n",
        "def REDUCE_JOB2(term, values):\n",
        "    df = 0\n",
        "    results = []\n",
        "    for doc_id, tf, count in values:\n",
        "        df += count\n",
        "        results.append((doc_id, tf))\n",
        "    for doc_id, tf in results:\n",
        "        yield ((term, doc_id), (tf, df))  #((Слово, ID документа), (TF, DF))\n",
        "\n",
        "# Job 3: Рассчитываем TF-IDF\n",
        "def RECORDREADER_JOB3():\n",
        "    for term_doc_pair, tf_df_pair in job2_output:\n",
        "        term, doc_id = term_doc_pair\n",
        "        tf, df = tf_df_pair\n",
        "        yield (term, (doc_id, tf, df))  #(Слово, (ID документа, TF, DF))\n",
        "\n",
        "def MAP_JOB3(term, doc_tf_df_pair, total_docs):\n",
        "    doc_id, tf, df = doc_tf_df_pair\n",
        "    idf = math.log(total_docs / df) if df != 0 else 0\n",
        "    tf_idf = tf * idf\n",
        "    yield ((term, doc_id), tf_idf)  #((Слово, ID документа), TF-IDF)\n",
        "\n",
        "def REDUCE_JOB3(term_doc_pair, values):\n",
        "    # Возвращаем ((Слово, ID документа), TF-IDF) для каждого значения\n",
        "    return [(term_doc_pair, value) for value in values]"
      ],
      "metadata": {
        "id": "AMjPk8aRc50-"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = {\n",
        "    \"doc1\": preprocess_text(\"Streaming data is the data from sensors as well as other real-time surveillance systems. Distributed stream processing systems are the software that manages such data. Such frameworks have to deliver outcomes on the go instantly. They are susceptible to delay and malfunction or system failures. The system must be tolerant of faults and always accessible. Many variables, such as improved network arrival rates, node failures, and so on, disrupt the system's reliability. Some operators need to be relocated online from one physical resource to another to manage or reimburse a slow or failing node. In this study, we propose a co-location based systematic migration heuristic for live operator migration between physical resources using a migration map revised with costs for each migration. The suggested method evaluates continuous operator performance patterns and makes online scheduling decisions based on the same. The decisions include migrating operators during a node failure or straggling.\"),\n",
        "    \"doc2\": preprocess_text(\"Distributed stream processing engines are designed with a focus on scalability to process big data volumes in a continuous manner. We present the Theodolite method for benchmarking the scalability of distributed stream processing engines. Core of this method is the definition of use cases that microservices implementing stream processing have to fulfill. For each use case, our method identifies relevant workload dimensions that might affect the scalability of a use case. We propose to design one benchmark per use case and relevant workload dimension. We present a general benchmarking framework, which can be applied to execute the individual benchmarks for a given use case and workload dimension. Our framework executes an implementation of the use case's dataflow architecture for different workloads of the given dimension and various numbers of processing instances. This way, it identifies how resources demand evolves with increasing workloads. Within the scope of this paper, we present 4 identified use cases, derived from processing Industrial Internet of Things data, and 7 corresponding workload dimensions. We provide implementations of 4 benchmarks with Kafka Streams and Apache Flink as well as an implementation of our benchmarking framework to execute scalability benchmarks in cloud environments. We use both for evaluating the Theodolite method and for benchmarking Kafka Streams' and Flink's scalability for different deployment options.\"),\n",
        "    \"doc3\": preprocess_text(\"Batch and stream processing are separately and efficiently applied in many applications. However, some newer data-driven applications such as the Internet of Things and cloud computing call for hybrid processing approaches in order to handle the speed and accuracy required for processing such complex data. In this paper, we propose a Hybrid Distributed Batch-Stream (HDBS) architecture for anomaly detection in real-time data. The hybrid architecture, while benefiting from the accuracy provided by batch processing, also enjoys the speed and real-time features of stream processing. In the proposed architecture, our focus is on the algorithmic aspects of hybrid processing including the interaction models between batch and stream processing units, the characteristics of batch and stream machine learning algorithms and the principles of merging the results of different processing units. The driving idea of such combination is that the results of batch and stream processing units are complementary with each other, as one of them constructs accurate models based on previous data, and the other one is capable of processing new stream data in real-time. Furthermore, we propose a generalized version of the HDBS with respect to its algorithms and communication policy levels. In the generalized HDBS architecture, we address the various aspects of the interaction between the batch and stream processing units, and the merging operations to produce the final results. the evaluations of the proposed architecture using various criteria (accuracy, space complexity, and time complexity) demonstrate that the accuracy of the proposed method is higher than the accuracy of the batch processing methods, its time complexity is also similar to one of the stream processing methods and much less than the batch processing methods, which makes our proposed architecture an efficient and practical solution for real-time anomaly detection.\"),\n",
        "    \"doc4\": preprocess_text(\"There have been increasing demands for real time processing of the ever-growing data. In order to meet this requirement and ensure the reliable processing of streaming data, a variety of distributed stream processing architectures and platforms have been developed, which handles the fundamental task of allocating processing tasks to the currently available physical resources and routing streaming data between these resources. However, many stream processing systems lack an intelligent scheduling mechanism, in which their default schedulers allocate tasks without taking resource demands and availability, or the transfer latency between resources into consideration. Besides, stream processing has a strict request for latency. Thus it is important to give latency guarantee for distributed stream processing. In this paper, we propose two new algorithms for stream processing with latency guarantee, both the algorithms consider transfer latency and resource demand in task allocation. Both algorithms can guarantee latency constraints. Algorithm AHA reduces more than 21.3% and 58.9% resources compared with the greedy and the round-robin algorithms, and algorithm PHA further improves the resource utilization to 32.1% and 73.2%.\"),\n",
        "    \"doc5\": preprocess_text(\"In the era of Big Data, typical architecture of distributed real-time stream processing systems is the combination of Flume, Kafka, and Storm. As a kind of distributed message system, Kafka has the characteristics of horizontal scalability and high throughput, which is manly deployed in many areas in order to address the problem of speed mismatch between message producers and consumers. When using Kafka, we need to quickly receive data sent by producers. In addition, we need to send data to consumers quickly. Therefore, the performance of Kafka is of critical importance to the performance of the whole stream processing system. In this paper, we propose the improved design of real-time stream processing systems, and focus on improving the Kafka’s data loading process. We use Kafka cat to transfer data from the source to Kafka topic directly, which can reduce the network transmission. We also utilize the memory file system to accelerate the process of data loading, which can address the bottleneck and performance problems caused by disk I/O. Extensive experiments are conducted to evaluate the performance, which show the superiority of our improved design.\"),\n",
        "    \"doc6\": preprocess_text(\"In this paper, nearly 40 commonly used deep neural network(DNN) models are selected, and their cross-platform and cross-inference frameworks are deeply analysed. The main metrics of accuracy, the total number of model parameters, the computational complexity, the accuracy density, the inference time, the memory consumption and other related parameters are used to measure their performance. The heterogeneous computing experiment is implemented on both the Google Colab cloud computing platform and the Jetson Nano embedded edge computing platform. The obtained performance is compared with that of two previous computing platforms: a workstation equipped with an NVIDIA Titan X Pascal and an embedded system based on an NVIDIA Jetson TX1 board. In addition, on the Jetson Nano embedded edge computing platform, different inference frameworks are investigated to evaluate the inference efficiency of the DNN models. Regression models are established to characterize the variation in the computing performance of different DNN classification algorithms so that the inference results of unknown models can be estimated. ANOVA methods are proposed to quantify the differences between models. The experimental results have important guiding significance for the better selection, deployment and application of DNN models in practice.\"),\n",
        "    \"doc7\": preprocess_text(\"Unmanned Aerial Vehicles (UAVs), which can operate autonomously in dynamic and complex environments, are becoming increasingly common. Deep learning techniques for motion control have recently taken a major qualitative step since vision-based inference tasks can be executed directly on edge. The goal is to fully integrate the machine learning (ML) element into small UAVs. However, given the limited payload capacity and energy available on small UAVs, integrating computing resources sufficient to host ML and vehicle control functions is still challenging. This paper presents a modular and generic system that can control the UAV by evaluating vision-based ML tasks directly inside the resource-constrained UAV. Two different vision-based navigation configurations were tested and demonstrated. The first configuration implements an autonomous landing site detection system, tested with two models based on LeNet-5 and MobileNetV2, respectively. This allows the UAV to change its planned path accordingly and approach the target to land. Moreover, a model for people detection based on a custom MobileNetV2 network was evaluated in the second configuration. Finally, the execution time and power consumption were measured and compared with a cloud computing approach. The results show the ability of the developed system to dynamically react to the environment to provide the necessary maneuver after detecting the target exploiting only the constrained computational resources of the UAV controller. Furthermore, we demonstrated that moving to the edge, instead of using cloud computing inference, decreases the energy requirement of the system without reducing the quality of service.\"),\n",
        "    \"doc8\": preprocess_text(\"With the continuous development of Internet of Things (IoT) and the overwhelming explosion of Big Data, edge computing serves as an efficient computing mode for time stringent data processing, which can bypass the constraints of network bandwidth and delay, and has been one of the foundation of interconnected applications. Although edge computing has gradually become one of bridges between cloud computing centers and mobile terminals, the literature still lacks a thorough review on the recent advances in edge computing platforms. In this paper, we firstly introduce the definition of edge computing and advantages of edge computing platform. And then, we summarize the key technologies of constructing an edge computing platform, and propose a general framework for edge computing platform. The role of distributed storage management systems in building edge computing platform is elaborated in detail. Furthermore, we give some applications to illustrate how to use third-party edge computing platforms to build specific applications. Finally, we briefly outline current open issues of edge computing platform based on our literature survey.\"),\n",
        "}\n",
        "\n",
        "# Job 1: Вычисляем TF\n",
        "input_data_1 = RECORDREADER_JOB1()\n",
        "job1_output = list(MapReduce(input_data_1, MAP_JOB1, REDUCE_JOB1))\n",
        "#print(\"Job 1 Output:\", job1_output)\n",
        "\n",
        "# Job 2: Вычисляем DF\n",
        "input_data_2 = RECORDREADER_JOB2()\n",
        "job2_output = list(MapReduce(input_data_2, MAP_JOB2, REDUCE_JOB2))\n",
        "#print(\"Job 2 Output:\", job2_output)\n",
        "\n",
        "# Job 3: Вычисляем TF-IDF\n",
        "total_docs = len(documents)\n",
        "input_data_3 = RECORDREADER_JOB3()\n",
        "job3_output = list(MapReduce(input_data_3, lambda term, doc_tf_df_pair: MAP_JOB3(term, doc_tf_df_pair, total_docs), REDUCE_JOB3))\n",
        "\n",
        "results_by_doc = defaultdict(list)\n",
        "for ((word, docname), tfidf) in job3_output:\n",
        "    results_by_doc[docname].append((word, tfidf))\n",
        "\n",
        "# Печатаем результаты\n",
        "for docname, words in results_by_doc.items():\n",
        "    print(f\"Document: {docname}\")\n",
        "    for word, tfidf in sorted(words):\n",
        "        print(f\"   {word}: {tfidf:.6f}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzcfSNgSdBdb",
        "outputId": "1a627f4f-ecca-4526-fb25-98f3f3c589d8"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document: doc1\n",
            "   a: 0.000000\n",
            "   accessible: 0.013863\n",
            "   always: 0.013863\n",
            "   and: 0.000000\n",
            "   another: 0.013863\n",
            "   are: 0.003836\n",
            "   arrival: 0.013863\n",
            "   as: 0.009400\n",
            "   based: 0.006267\n",
            "   be: 0.009242\n",
            "   between: 0.001918\n",
            "   colocation: 0.013863\n",
            "   continuous: 0.006539\n",
            "   costs: 0.013863\n",
            "   data: 0.005754\n",
            "   decisions: 0.027726\n",
            "   delay: 0.009242\n",
            "   deliver: 0.013863\n",
            "   disrupt: 0.013863\n",
            "   distributed: 0.001918\n",
            "   during: 0.013863\n",
            "   each: 0.006539\n",
            "   evaluates: 0.013863\n",
            "   failing: 0.013863\n",
            "   failure: 0.013863\n",
            "   failures: 0.027726\n",
            "   faults: 0.013863\n",
            "   for: 0.001780\n",
            "   frameworks: 0.009242\n",
            "   from: 0.009242\n",
            "   go: 0.013863\n",
            "   have: 0.003133\n",
            "   heuristic: 0.013863\n",
            "   improved: 0.009242\n",
            "   in: 0.000000\n",
            "   include: 0.013863\n",
            "   instantly: 0.013863\n",
            "   is: 0.000000\n",
            "   live: 0.013863\n",
            "   makes: 0.009242\n",
            "   malfunction: 0.013863\n",
            "   manage: 0.013863\n",
            "   manages: 0.013863\n",
            "   many: 0.004621\n",
            "   map: 0.013863\n",
            "   method: 0.006539\n",
            "   migrating: 0.013863\n",
            "   migration: 0.055452\n",
            "   must: 0.013863\n",
            "   need: 0.009242\n",
            "   network: 0.004621\n",
            "   node: 0.041589\n",
            "   of: 0.000000\n",
            "   on: 0.002671\n",
            "   one: 0.004621\n",
            "   online: 0.027726\n",
            "   operator: 0.027726\n",
            "   operators: 0.027726\n",
            "   or: 0.036968\n",
            "   other: 0.006539\n",
            "   outcomes: 0.013863\n",
            "   patterns: 0.013863\n",
            "   performance: 0.006539\n",
            "   physical: 0.018484\n",
            "   processing: 0.001918\n",
            "   propose: 0.001918\n",
            "   rates: 0.013863\n",
            "   realtime: 0.006539\n",
            "   reimburse: 0.013863\n",
            "   reliability: 0.013863\n",
            "   relocated: 0.013863\n",
            "   resource: 0.009242\n",
            "   resources: 0.004621\n",
            "   revised: 0.013863\n",
            "   same: 0.013863\n",
            "   scheduling: 0.009242\n",
            "   sensors: 0.013863\n",
            "   slow: 0.013863\n",
            "   so: 0.009242\n",
            "   software: 0.013863\n",
            "   some: 0.006539\n",
            "   straggling: 0.013863\n",
            "   stream: 0.003133\n",
            "   streaming: 0.009242\n",
            "   study: 0.013863\n",
            "   such: 0.027726\n",
            "   suggested: 0.013863\n",
            "   surveillance: 0.013863\n",
            "   susceptible: 0.013863\n",
            "   system: 0.009242\n",
            "   systematic: 0.013863\n",
            "   systems: 0.013863\n",
            "   that: 0.003133\n",
            "   the: 0.000000\n",
            "   they: 0.013863\n",
            "   this: 0.000000\n",
            "   to: 0.000000\n",
            "   tolerant: 0.013863\n",
            "   using: 0.004621\n",
            "   variables: 0.013863\n",
            "   we: 0.000890\n",
            "   well: 0.009242\n",
            "   with: 0.000890\n",
            "\n",
            "Document: doc4\n",
            "   213: 0.011951\n",
            "   321: 0.011951\n",
            "   589: 0.011951\n",
            "   732: 0.011951\n",
            "   a: 0.000000\n",
            "   aha: 0.011951\n",
            "   algorithm: 0.023902\n",
            "   algorithms: 0.022548\n",
            "   allocate: 0.011951\n",
            "   allocating: 0.011951\n",
            "   allocation: 0.011951\n",
            "   an: 0.001653\n",
            "   and: 0.000000\n",
            "   architectures: 0.011951\n",
            "   availability: 0.011951\n",
            "   available: 0.007967\n",
            "   been: 0.015934\n",
            "   besides: 0.011951\n",
            "   between: 0.003307\n",
            "   both: 0.011274\n",
            "   can: 0.001653\n",
            "   compared: 0.005637\n",
            "   consider: 0.011951\n",
            "   consideration: 0.011951\n",
            "   constraints: 0.007967\n",
            "   currently: 0.011951\n",
            "   data: 0.004960\n",
            "   default: 0.011951\n",
            "   demand: 0.007967\n",
            "   demands: 0.023902\n",
            "   developed: 0.007967\n",
            "   distributed: 0.003307\n",
            "   ensure: 0.011951\n",
            "   evergrowing: 0.011951\n",
            "   for: 0.003070\n",
            "   fundamental: 0.011951\n",
            "   further: 0.011951\n",
            "   give: 0.007967\n",
            "   greedy: 0.011951\n",
            "   guarantee: 0.035852\n",
            "   handles: 0.011951\n",
            "   has: 0.005637\n",
            "   have: 0.005402\n",
            "   however: 0.005637\n",
            "   important: 0.007967\n",
            "   improves: 0.011951\n",
            "   in: 0.000000\n",
            "   increasing: 0.007967\n",
            "   intelligent: 0.011951\n",
            "   into: 0.007967\n",
            "   is: 0.000000\n",
            "   it: 0.007967\n",
            "   lack: 0.011951\n",
            "   latency: 0.071705\n",
            "   many: 0.003984\n",
            "   mechanism: 0.011951\n",
            "   meet: 0.011951\n",
            "   more: 0.011951\n",
            "   new: 0.007967\n",
            "   of: 0.000000\n",
            "   or: 0.007967\n",
            "   order: 0.005637\n",
            "   paper: 0.000767\n",
            "   pha: 0.011951\n",
            "   physical: 0.007967\n",
            "   platforms: 0.005637\n",
            "   processing: 0.013227\n",
            "   propose: 0.001653\n",
            "   real: 0.011951\n",
            "   reduces: 0.011951\n",
            "   reliable: 0.011951\n",
            "   request: 0.011951\n",
            "   requirement: 0.007967\n",
            "   resource: 0.023902\n",
            "   resources: 0.015934\n",
            "   roundrobin: 0.011951\n",
            "   routing: 0.011951\n",
            "   schedulers: 0.011951\n",
            "   scheduling: 0.007967\n",
            "   stream: 0.013506\n",
            "   streaming: 0.015934\n",
            "   strict: 0.011951\n",
            "   systems: 0.003984\n",
            "   taking: 0.011951\n",
            "   task: 0.023902\n",
            "   tasks: 0.015934\n",
            "   than: 0.007967\n",
            "   the: 0.000000\n",
            "   their: 0.007967\n",
            "   there: 0.011951\n",
            "   these: 0.011951\n",
            "   this: 0.000000\n",
            "   thus: 0.011951\n",
            "   time: 0.002701\n",
            "   to: 0.000000\n",
            "   transfer: 0.015934\n",
            "   two: 0.005637\n",
            "   utilization: 0.011951\n",
            "   variety: 0.011951\n",
            "   we: 0.000767\n",
            "   which: 0.003307\n",
            "   with: 0.001535\n",
            "   without: 0.007967\n",
            "\n",
            "Document: doc2\n",
            "   4: 0.019344\n",
            "   7: 0.009672\n",
            "   a: 0.000000\n",
            "   affect: 0.009672\n",
            "   an: 0.002676\n",
            "   and: 0.000000\n",
            "   apache: 0.009672\n",
            "   applied: 0.006448\n",
            "   architecture: 0.004562\n",
            "   are: 0.001338\n",
            "   as: 0.004372\n",
            "   be: 0.003224\n",
            "   benchmark: 0.009672\n",
            "   benchmarking: 0.038687\n",
            "   benchmarks: 0.029015\n",
            "   big: 0.004562\n",
            "   both: 0.004562\n",
            "   can: 0.001338\n",
            "   case: 0.038687\n",
            "   cases: 0.029015\n",
            "   cloud: 0.002186\n",
            "   continuous: 0.004562\n",
            "   core: 0.009672\n",
            "   corresponding: 0.009672\n",
            "   data: 0.002676\n",
            "   dataflow: 0.009672\n",
            "   definition: 0.006448\n",
            "   demand: 0.006448\n",
            "   deployment: 0.006448\n",
            "   derived: 0.009672\n",
            "   design: 0.006448\n",
            "   designed: 0.009672\n",
            "   different: 0.006448\n",
            "   dimension: 0.029015\n",
            "   dimensions: 0.019344\n",
            "   distributed: 0.002676\n",
            "   each: 0.004562\n",
            "   engines: 0.019344\n",
            "   environments: 0.006448\n",
            "   evaluating: 0.006448\n",
            "   evolves: 0.009672\n",
            "   execute: 0.019344\n",
            "   executes: 0.009672\n",
            "   flink: 0.009672\n",
            "   flinks: 0.009672\n",
            "   focus: 0.004562\n",
            "   for: 0.004348\n",
            "   framework: 0.019344\n",
            "   from: 0.003224\n",
            "   fulfill: 0.009672\n",
            "   general: 0.006448\n",
            "   given: 0.012896\n",
            "   have: 0.002186\n",
            "   how: 0.006448\n",
            "   identified: 0.009672\n",
            "   identifies: 0.019344\n",
            "   implementation: 0.019344\n",
            "   implementations: 0.009672\n",
            "   implementing: 0.009672\n",
            "   in: 0.000000\n",
            "   increasing: 0.006448\n",
            "   individual: 0.009672\n",
            "   industrial: 0.009672\n",
            "   instances: 0.009672\n",
            "   internet: 0.004562\n",
            "   is: 0.000000\n",
            "   it: 0.006448\n",
            "   kafka: 0.012896\n",
            "   manner: 0.009672\n",
            "   method: 0.018248\n",
            "   microservices: 0.009672\n",
            "   might: 0.009672\n",
            "   numbers: 0.009672\n",
            "   of: 0.000000\n",
            "   on: 0.000621\n",
            "   one: 0.003224\n",
            "   options: 0.009672\n",
            "   our: 0.009672\n",
            "   paper: 0.000621\n",
            "   per: 0.009672\n",
            "   present: 0.029015\n",
            "   process: 0.006448\n",
            "   processing: 0.006690\n",
            "   propose: 0.001338\n",
            "   provide: 0.006448\n",
            "   relevant: 0.019344\n",
            "   resources: 0.003224\n",
            "   scalability: 0.032239\n",
            "   scope: 0.009672\n",
            "   stream: 0.006558\n",
            "   streams: 0.019344\n",
            "   that: 0.004372\n",
            "   the: 0.000000\n",
            "   theodolite: 0.019344\n",
            "   things: 0.004562\n",
            "   this: 0.000000\n",
            "   to: 0.000000\n",
            "   use: 0.036496\n",
            "   various: 0.006448\n",
            "   volumes: 0.009672\n",
            "   way: 0.009672\n",
            "   we: 0.003726\n",
            "   well: 0.006448\n",
            "   which: 0.001338\n",
            "   with: 0.001863\n",
            "   within: 0.009672\n",
            "   workload: 0.038687\n",
            "   workloads: 0.019344\n",
            "\n",
            "Document: doc3\n",
            "   a: 0.000000\n",
            "   accuracy: 0.024068\n",
            "   accurate: 0.007220\n",
            "   address: 0.004814\n",
            "   algorithmic: 0.007220\n",
            "   algorithms: 0.006811\n",
            "   also: 0.009627\n",
            "   an: 0.000999\n",
            "   and: 0.000000\n",
            "   anomaly: 0.014441\n",
            "   applications: 0.009627\n",
            "   applied: 0.004814\n",
            "   approaches: 0.007220\n",
            "   architecture: 0.020434\n",
            "   are: 0.001998\n",
            "   as: 0.003264\n",
            "   aspects: 0.014441\n",
            "   based: 0.001632\n",
            "   batch: 0.057762\n",
            "   batchstream: 0.007220\n",
            "   benefiting: 0.007220\n",
            "   between: 0.001998\n",
            "   by: 0.003406\n",
            "   call: 0.007220\n",
            "   capable: 0.007220\n",
            "   characteristics: 0.004814\n",
            "   cloud: 0.001632\n",
            "   combination: 0.004814\n",
            "   communication: 0.007220\n",
            "   complementary: 0.007220\n",
            "   complex: 0.004814\n",
            "   complexity: 0.014441\n",
            "   computing: 0.002407\n",
            "   constructs: 0.007220\n",
            "   criteria: 0.007220\n",
            "   data: 0.003996\n",
            "   datadriven: 0.007220\n",
            "   demonstrate: 0.007220\n",
            "   detection: 0.009627\n",
            "   different: 0.002407\n",
            "   distributed: 0.000999\n",
            "   driving: 0.007220\n",
            "   each: 0.003406\n",
            "   efficient: 0.004814\n",
            "   efficiently: 0.007220\n",
            "   enjoys: 0.007220\n",
            "   evaluations: 0.007220\n",
            "   features: 0.007220\n",
            "   final: 0.007220\n",
            "   focus: 0.003406\n",
            "   for: 0.001855\n",
            "   from: 0.002407\n",
            "   furthermore: 0.003406\n",
            "   generalized: 0.014441\n",
            "   handle: 0.007220\n",
            "   hdbs: 0.021661\n",
            "   higher: 0.007220\n",
            "   however: 0.003406\n",
            "   hybrid: 0.028881\n",
            "   idea: 0.007220\n",
            "   in: 0.000000\n",
            "   including: 0.007220\n",
            "   interaction: 0.014441\n",
            "   internet: 0.003406\n",
            "   is: 0.000000\n",
            "   its: 0.009627\n",
            "   learning: 0.004814\n",
            "   less: 0.007220\n",
            "   levels: 0.007220\n",
            "   machine: 0.004814\n",
            "   makes: 0.004814\n",
            "   many: 0.002407\n",
            "   merging: 0.014441\n",
            "   method: 0.003406\n",
            "   methods: 0.014441\n",
            "   models: 0.006811\n",
            "   much: 0.007220\n",
            "   new: 0.004814\n",
            "   newer: 0.007220\n",
            "   of: 0.000000\n",
            "   on: 0.000927\n",
            "   one: 0.007220\n",
            "   operations: 0.007220\n",
            "   order: 0.003406\n",
            "   other: 0.006811\n",
            "   our: 0.004814\n",
            "   paper: 0.000464\n",
            "   policy: 0.007220\n",
            "   practical: 0.007220\n",
            "   previous: 0.004814\n",
            "   principles: 0.007220\n",
            "   processing: 0.013985\n",
            "   produce: 0.007220\n",
            "   propose: 0.001998\n",
            "   proposed: 0.019254\n",
            "   provided: 0.007220\n",
            "   realtime: 0.013623\n",
            "   required: 0.007220\n",
            "   respect: 0.007220\n",
            "   results: 0.010217\n",
            "   separately: 0.007220\n",
            "   similar: 0.007220\n",
            "   solution: 0.007220\n",
            "   some: 0.003406\n",
            "   space: 0.007220\n",
            "   speed: 0.009627\n",
            "   stream: 0.013056\n",
            "   such: 0.014441\n",
            "   than: 0.009627\n",
            "   that: 0.003264\n",
            "   the: 0.000000\n",
            "   them: 0.007220\n",
            "   things: 0.003406\n",
            "   this: 0.000000\n",
            "   time: 0.003264\n",
            "   to: 0.000000\n",
            "   units: 0.028881\n",
            "   using: 0.002407\n",
            "   various: 0.009627\n",
            "   version: 0.007220\n",
            "   we: 0.001391\n",
            "   which: 0.000999\n",
            "   while: 0.007220\n",
            "   with: 0.000927\n",
            "\n",
            "Document: doc5\n",
            "   a: 0.000000\n",
            "   accelerate: 0.011301\n",
            "   addition: 0.007534\n",
            "   address: 0.015068\n",
            "   also: 0.007534\n",
            "   and: 0.000000\n",
            "   architecture: 0.005331\n",
            "   are: 0.001563\n",
            "   areas: 0.011301\n",
            "   as: 0.002554\n",
            "   between: 0.001563\n",
            "   big: 0.005331\n",
            "   bottleneck: 0.011301\n",
            "   by: 0.010661\n",
            "   can: 0.003127\n",
            "   cat: 0.011301\n",
            "   caused: 0.011301\n",
            "   characteristics: 0.007534\n",
            "   combination: 0.007534\n",
            "   conducted: 0.011301\n",
            "   consumers: 0.022603\n",
            "   critical: 0.011301\n",
            "   data: 0.009381\n",
            "   deployed: 0.011301\n",
            "   design: 0.015068\n",
            "   directly: 0.007534\n",
            "   disk: 0.011301\n",
            "   distributed: 0.003127\n",
            "   era: 0.011301\n",
            "   evaluate: 0.007534\n",
            "   experiments: 0.011301\n",
            "   extensive: 0.011301\n",
            "   file: 0.011301\n",
            "   flume: 0.011301\n",
            "   focus: 0.005331\n",
            "   from: 0.003767\n",
            "   has: 0.005331\n",
            "   high: 0.011301\n",
            "   horizontal: 0.011301\n",
            "   importance: 0.011301\n",
            "   improved: 0.015068\n",
            "   improving: 0.011301\n",
            "   in: 0.000000\n",
            "   io: 0.011301\n",
            "   is: 0.000000\n",
            "   kafka: 0.045205\n",
            "   kafka’s: 0.011301\n",
            "   kind: 0.011301\n",
            "   loading: 0.022603\n",
            "   manly: 0.011301\n",
            "   many: 0.003767\n",
            "   memory: 0.007534\n",
            "   message: 0.022603\n",
            "   mismatch: 0.011301\n",
            "   need: 0.015068\n",
            "   network: 0.003767\n",
            "   of: 0.000000\n",
            "   on: 0.000726\n",
            "   order: 0.005331\n",
            "   our: 0.003767\n",
            "   paper: 0.000726\n",
            "   performance: 0.021322\n",
            "   problem: 0.011301\n",
            "   problems: 0.011301\n",
            "   process: 0.015068\n",
            "   processing: 0.004690\n",
            "   producers: 0.022603\n",
            "   propose: 0.001563\n",
            "   quickly: 0.022603\n",
            "   realtime: 0.010661\n",
            "   receive: 0.011301\n",
            "   reduce: 0.011301\n",
            "   scalability: 0.007534\n",
            "   send: 0.011301\n",
            "   sent: 0.011301\n",
            "   show: 0.007534\n",
            "   source: 0.011301\n",
            "   speed: 0.007534\n",
            "   storm: 0.011301\n",
            "   stream: 0.007663\n",
            "   superiority: 0.011301\n",
            "   system: 0.011301\n",
            "   systems: 0.007534\n",
            "   the: 0.000000\n",
            "   therefore: 0.011301\n",
            "   this: 0.000000\n",
            "   throughput: 0.011301\n",
            "   to: 0.000000\n",
            "   topic: 0.011301\n",
            "   transfer: 0.007534\n",
            "   transmission: 0.011301\n",
            "   typical: 0.011301\n",
            "   use: 0.005331\n",
            "   using: 0.003767\n",
            "   utilize: 0.011301\n",
            "   we: 0.003629\n",
            "   when: 0.011301\n",
            "   which: 0.006254\n",
            "   whole: 0.011301\n",
            "\n",
            "Document: doc8\n",
            "   a: 0.000000\n",
            "   advances: 0.012304\n",
            "   advantages: 0.012304\n",
            "   although: 0.012304\n",
            "   an: 0.003405\n",
            "   and: 0.000000\n",
            "   applications: 0.024609\n",
            "   as: 0.002781\n",
            "   bandwidth: 0.012304\n",
            "   based: 0.002781\n",
            "   become: 0.012304\n",
            "   been: 0.008203\n",
            "   between: 0.001702\n",
            "   big: 0.005804\n",
            "   bridges: 0.012304\n",
            "   briefly: 0.012304\n",
            "   build: 0.012304\n",
            "   building: 0.012304\n",
            "   bypass: 0.012304\n",
            "   can: 0.001702\n",
            "   centers: 0.012304\n",
            "   cloud: 0.002781\n",
            "   computing: 0.049218\n",
            "   constraints: 0.008203\n",
            "   constructing: 0.012304\n",
            "   continuous: 0.005804\n",
            "   current: 0.012304\n",
            "   data: 0.003405\n",
            "   definition: 0.008203\n",
            "   delay: 0.008203\n",
            "   detail: 0.012304\n",
            "   development: 0.012304\n",
            "   distributed: 0.001702\n",
            "   edge: 0.058037\n",
            "   efficient: 0.008203\n",
            "   elaborated: 0.012304\n",
            "   explosion: 0.012304\n",
            "   finally: 0.008203\n",
            "   firstly: 0.012304\n",
            "   for: 0.001580\n",
            "   foundation: 0.012304\n",
            "   framework: 0.008203\n",
            "   furthermore: 0.005804\n",
            "   general: 0.008203\n",
            "   give: 0.008203\n",
            "   gradually: 0.012304\n",
            "   has: 0.011607\n",
            "   how: 0.008203\n",
            "   illustrate: 0.012304\n",
            "   in: 0.000000\n",
            "   interconnected: 0.012304\n",
            "   internet: 0.005804\n",
            "   introduce: 0.012304\n",
            "   iot: 0.012304\n",
            "   is: 0.000000\n",
            "   issues: 0.012304\n",
            "   key: 0.012304\n",
            "   lacks: 0.012304\n",
            "   literature: 0.024609\n",
            "   management: 0.012304\n",
            "   mobile: 0.012304\n",
            "   mode: 0.012304\n",
            "   network: 0.004101\n",
            "   of: 0.000000\n",
            "   on: 0.001580\n",
            "   one: 0.008203\n",
            "   open: 0.012304\n",
            "   our: 0.004101\n",
            "   outline: 0.012304\n",
            "   overwhelming: 0.012304\n",
            "   paper: 0.000790\n",
            "   platform: 0.041015\n",
            "   platforms: 0.011607\n",
            "   processing: 0.001702\n",
            "   propose: 0.001702\n",
            "   recent: 0.012304\n",
            "   review: 0.012304\n",
            "   role: 0.012304\n",
            "   serves: 0.012304\n",
            "   some: 0.005804\n",
            "   specific: 0.012304\n",
            "   still: 0.008203\n",
            "   storage: 0.012304\n",
            "   stringent: 0.012304\n",
            "   summarize: 0.012304\n",
            "   survey: 0.012304\n",
            "   systems: 0.004101\n",
            "   technologies: 0.012304\n",
            "   terminals: 0.012304\n",
            "   the: 0.000000\n",
            "   then: 0.012304\n",
            "   things: 0.005804\n",
            "   thirdparty: 0.012304\n",
            "   this: 0.000000\n",
            "   thorough: 0.012304\n",
            "   time: 0.002781\n",
            "   to: 0.000000\n",
            "   use: 0.005804\n",
            "   we: 0.003161\n",
            "   which: 0.001702\n",
            "   with: 0.000790\n",
            "\n",
            "Document: doc6\n",
            "   40: 0.010944\n",
            "   a: 0.000000\n",
            "   accuracy: 0.014593\n",
            "   addition: 0.007296\n",
            "   algorithms: 0.005162\n",
            "   an: 0.004542\n",
            "   analysed: 0.010944\n",
            "   and: 0.000000\n",
            "   anova: 0.010944\n",
            "   application: 0.010944\n",
            "   are: 0.009085\n",
            "   based: 0.002474\n",
            "   be: 0.003648\n",
            "   better: 0.010944\n",
            "   between: 0.001514\n",
            "   board: 0.010944\n",
            "   both: 0.005162\n",
            "   can: 0.001514\n",
            "   characterize: 0.010944\n",
            "   classification: 0.010944\n",
            "   cloud: 0.002474\n",
            "   colab: 0.010944\n",
            "   commonly: 0.010944\n",
            "   compared: 0.005162\n",
            "   complexity: 0.007296\n",
            "   computational: 0.007296\n",
            "   computing: 0.021889\n",
            "   consumption: 0.007296\n",
            "   crossinference: 0.010944\n",
            "   crossplatform: 0.010944\n",
            "   deep: 0.007296\n",
            "   deeply: 0.010944\n",
            "   density: 0.010944\n",
            "   deployment: 0.007296\n",
            "   differences: 0.010944\n",
            "   different: 0.007296\n",
            "   dnn: 0.032833\n",
            "   edge: 0.010325\n",
            "   efficiency: 0.010944\n",
            "   embedded: 0.032833\n",
            "   equipped: 0.010944\n",
            "   established: 0.010944\n",
            "   estimated: 0.010944\n",
            "   evaluate: 0.007296\n",
            "   experiment: 0.010944\n",
            "   experimental: 0.010944\n",
            "   for: 0.000703\n",
            "   frameworks: 0.014593\n",
            "   google: 0.010944\n",
            "   guiding: 0.010944\n",
            "   have: 0.002474\n",
            "   heterogeneous: 0.010944\n",
            "   implemented: 0.010944\n",
            "   important: 0.007296\n",
            "   in: 0.000000\n",
            "   inference: 0.029185\n",
            "   investigated: 0.010944\n",
            "   is: 0.000000\n",
            "   jetson: 0.032833\n",
            "   main: 0.010944\n",
            "   measure: 0.010944\n",
            "   memory: 0.007296\n",
            "   methods: 0.007296\n",
            "   metrics: 0.010944\n",
            "   model: 0.007296\n",
            "   models: 0.030974\n",
            "   nano: 0.021889\n",
            "   nearly: 0.010944\n",
            "   networkdnn: 0.010944\n",
            "   neural: 0.010944\n",
            "   number: 0.010944\n",
            "   nvidia: 0.021889\n",
            "   obtained: 0.010944\n",
            "   of: 0.000000\n",
            "   on: 0.002108\n",
            "   other: 0.005162\n",
            "   paper: 0.000703\n",
            "   parameters: 0.021889\n",
            "   pascal: 0.010944\n",
            "   performance: 0.015487\n",
            "   platform: 0.021889\n",
            "   platforms: 0.005162\n",
            "   practice: 0.010944\n",
            "   previous: 0.007296\n",
            "   proposed: 0.007296\n",
            "   quantify: 0.010944\n",
            "   regression: 0.010944\n",
            "   related: 0.010944\n",
            "   results: 0.010325\n",
            "   selected: 0.010944\n",
            "   selection: 0.010944\n",
            "   significance: 0.010944\n",
            "   so: 0.007296\n",
            "   system: 0.003648\n",
            "   that: 0.004947\n",
            "   the: 0.000000\n",
            "   their: 0.014593\n",
            "   this: 0.000000\n",
            "   time: 0.002474\n",
            "   titan: 0.010944\n",
            "   to: 0.000000\n",
            "   total: 0.010944\n",
            "   two: 0.005162\n",
            "   tx1: 0.010944\n",
            "   unknown: 0.010944\n",
            "   used: 0.021889\n",
            "   variation: 0.010944\n",
            "   with: 0.001406\n",
            "   workstation: 0.010944\n",
            "   x: 0.010944\n",
            "\n",
            "Document: doc7\n",
            "   a: 0.000000\n",
            "   ability: 0.008557\n",
            "   accordingly: 0.008557\n",
            "   aerial: 0.008557\n",
            "   after: 0.008557\n",
            "   allows: 0.008557\n",
            "   an: 0.001184\n",
            "   and: 0.000000\n",
            "   approach: 0.017115\n",
            "   are: 0.001184\n",
            "   autonomous: 0.008557\n",
            "   autonomously: 0.008557\n",
            "   available: 0.005705\n",
            "   based: 0.003868\n",
            "   be: 0.002852\n",
            "   becoming: 0.008557\n",
            "   by: 0.004036\n",
            "   can: 0.003552\n",
            "   capacity: 0.008557\n",
            "   challenging: 0.008557\n",
            "   change: 0.008557\n",
            "   cloud: 0.003868\n",
            "   common: 0.008557\n",
            "   compared: 0.004036\n",
            "   complex: 0.005705\n",
            "   computational: 0.005705\n",
            "   computing: 0.008557\n",
            "   configuration: 0.017115\n",
            "   configurations: 0.008557\n",
            "   constrained: 0.008557\n",
            "   consumption: 0.005705\n",
            "   control: 0.025672\n",
            "   controller: 0.008557\n",
            "   custom: 0.008557\n",
            "   decreases: 0.008557\n",
            "   deep: 0.005705\n",
            "   demonstrated: 0.017115\n",
            "   detecting: 0.008557\n",
            "   detection: 0.011410\n",
            "   developed: 0.005705\n",
            "   different: 0.002852\n",
            "   directly: 0.011410\n",
            "   dynamic: 0.008557\n",
            "   dynamically: 0.008557\n",
            "   edge: 0.008073\n",
            "   element: 0.008557\n",
            "   energy: 0.017115\n",
            "   environment: 0.008557\n",
            "   environments: 0.005705\n",
            "   evaluated: 0.008557\n",
            "   evaluating: 0.005705\n",
            "   executed: 0.008557\n",
            "   execution: 0.008557\n",
            "   exploiting: 0.008557\n",
            "   finally: 0.005705\n",
            "   first: 0.008557\n",
            "   for: 0.001099\n",
            "   fully: 0.008557\n",
            "   functions: 0.008557\n",
            "   furthermore: 0.004036\n",
            "   generic: 0.008557\n",
            "   given: 0.005705\n",
            "   goal: 0.008557\n",
            "   have: 0.001934\n",
            "   host: 0.008557\n",
            "   however: 0.004036\n",
            "   implements: 0.008557\n",
            "   in: 0.000000\n",
            "   increasingly: 0.008557\n",
            "   inference: 0.011410\n",
            "   inside: 0.008557\n",
            "   instead: 0.008557\n",
            "   integrate: 0.008557\n",
            "   integrating: 0.008557\n",
            "   into: 0.005705\n",
            "   is: 0.000000\n",
            "   its: 0.005705\n",
            "   land: 0.008557\n",
            "   landing: 0.008557\n",
            "   learning: 0.011410\n",
            "   lenet5: 0.008557\n",
            "   limited: 0.008557\n",
            "   machine: 0.005705\n",
            "   major: 0.008557\n",
            "   maneuver: 0.008557\n",
            "   measured: 0.008557\n",
            "   ml: 0.025672\n",
            "   mobilenetv2: 0.017115\n",
            "   model: 0.005705\n",
            "   models: 0.004036\n",
            "   modular: 0.008557\n",
            "   moreover: 0.008557\n",
            "   motion: 0.008557\n",
            "   moving: 0.008557\n",
            "   navigation: 0.008557\n",
            "   necessary: 0.008557\n",
            "   network: 0.002852\n",
            "   of: 0.000000\n",
            "   on: 0.002198\n",
            "   only: 0.008557\n",
            "   operate: 0.008557\n",
            "   paper: 0.000550\n",
            "   path: 0.008557\n",
            "   payload: 0.008557\n",
            "   people: 0.008557\n",
            "   planned: 0.008557\n",
            "   power: 0.008557\n",
            "   presents: 0.008557\n",
            "   provide: 0.005705\n",
            "   qualitative: 0.008557\n",
            "   quality: 0.008557\n",
            "   react: 0.008557\n",
            "   recently: 0.008557\n",
            "   reducing: 0.008557\n",
            "   requirement: 0.005705\n",
            "   resourceconstrained: 0.008557\n",
            "   resources: 0.005705\n",
            "   respectively: 0.008557\n",
            "   results: 0.004036\n",
            "   second: 0.008557\n",
            "   service: 0.008557\n",
            "   show: 0.005705\n",
            "   since: 0.008557\n",
            "   site: 0.008557\n",
            "   small: 0.017115\n",
            "   step: 0.008557\n",
            "   still: 0.005705\n",
            "   sufficient: 0.008557\n",
            "   system: 0.011410\n",
            "   taken: 0.008557\n",
            "   target: 0.017115\n",
            "   tasks: 0.011410\n",
            "   techniques: 0.008557\n",
            "   tested: 0.017115\n",
            "   that: 0.003868\n",
            "   the: 0.000000\n",
            "   this: 0.000000\n",
            "   time: 0.001934\n",
            "   to: 0.000000\n",
            "   two: 0.008073\n",
            "   uav: 0.034229\n",
            "   uavs: 0.025672\n",
            "   unmanned: 0.008557\n",
            "   using: 0.002852\n",
            "   vehicle: 0.008557\n",
            "   vehicles: 0.008557\n",
            "   visionbased: 0.025672\n",
            "   was: 0.008557\n",
            "   we: 0.000550\n",
            "   were: 0.017115\n",
            "   which: 0.001184\n",
            "   with: 0.001099\n",
            "   without: 0.005705\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Breadth-First Search\n",
        "Алгоритм параллельного поиска в ширину  \n",
        "Найти кратчайший путь от вершины 0 до вершины 19"
      ],
      "metadata": {
        "id": "blKZqDO4rZag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(nested_iterable):\n",
        "    for iterable in nested_iterable:\n",
        "        for element in iterable:\n",
        "            yield element\n",
        "\n",
        "def groupbykey(iterable):\n",
        "    t = {}\n",
        "    for (k2, v2) in iterable:\n",
        "        t[k2] = t.get(k2, []) + [v2]\n",
        "    return t.items()\n",
        "\n",
        "def MapReduce(INPUTREADER, MAP, REDUCE):\n",
        "    return flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), INPUTREADER())))))\n",
        "\n",
        "\n",
        "class Node(NamedTuple):\n",
        "    id: int\n",
        "    adj_list: list[int]\n",
        "    distance: int\n",
        "\n",
        "graph_lst = {\n",
        "    0: [1, 3],\n",
        "    1: [0, 2, 4],\n",
        "    2: [1, 3, 5, 6],\n",
        "    3: [0, 2, 8],\n",
        "    4: [1, 10, 11],\n",
        "    5: [2, 8, 10],\n",
        "    6: [2, 7],\n",
        "    7: [6, 12],\n",
        "    8: [3, 5, 7, 9],\n",
        "    9: [8, 10],\n",
        "    10: [4, 5, 9, 11, 16],\n",
        "    11: [4, 10, 13],\n",
        "    12: [7, 14],\n",
        "    13: [11, 14],\n",
        "    14: [12, 13, 15],\n",
        "    15: [14, 16],\n",
        "    16: [10, 15, 17],\n",
        "    17: [16, 18],\n",
        "    18: [17, 19],\n",
        "    19: [18]\n",
        "}\n",
        "\n",
        "# Функция создания графа\n",
        "def GRAPHCREATER():\n",
        "    return [(n, Node(id=n, adj_list=nn, distance=100)) for n, nn in graph_lst.items()]\n",
        "\n",
        "# Функция для начала поиска (для вершины 0)\n",
        "def initialize_graph():\n",
        "    graph_struct = GRAPHCREATER()\n",
        "    N = graph_struct[0][1]\n",
        "    N1 = Node(N.id, N.adj_list, 0)  # Начинаем с вершины 0 с расстоянием 0\n",
        "    graph_struct[0] = (N.id, N1)\n",
        "    return graph_struct\n",
        "\n",
        "# Функция MAP (поиск соседей и обновление расстояния)\n",
        "def MAP(n: int, N: Node):\n",
        "    d = N.distance\n",
        "    for m in N.adj_list:\n",
        "        yield (m, d + 1)\n",
        "\n",
        "# Функция REDUCE (выбор минимального расстояния для каждой вершины)\n",
        "def REDUCE(m: int, distances: Iterator[int]):\n",
        "    dmin = min(distances)\n",
        "    yield (m, dmin)\n",
        "\n",
        "# Чтение данных для MapReduce\n",
        "def READER():\n",
        "    for i, m in output:\n",
        "        N = graph_struct[i][1]\n",
        "        yield (i, Node(N.id, N.adj_list, m))\n",
        "\n",
        "graph_struct = initialize_graph()\n",
        "\n",
        "output = [(0, 0)]\n",
        "\n",
        "for iteration in range(1, len(graph_lst) + 1):  # Делаем максимум N итераций, где N - количество вершин\n",
        "    print(f\"Итерация {iteration}:\")\n",
        "\n",
        "    output = MapReduce(READER, MAP, REDUCE)\n",
        "    output = list(output)\n",
        "\n",
        "    # Обновляем граф на основе результатов MapReduce\n",
        "    updated_nodes = []  # Список обновленных вершин\n",
        "    for i, d in output:\n",
        "        M = graph_struct[i][1]\n",
        "        if M.distance == 100:  # Если вершина не была посещена, обновляем её\n",
        "            graph_struct[i] = (i, Node(M.id, M.adj_list, d))\n",
        "            updated_nodes.append(i)\n",
        "\n",
        "    if updated_nodes:\n",
        "        print(f\"Обновленные вершины: {updated_nodes}\")\n",
        "    else:\n",
        "        print(\"Нет обновлений на этой итерации\")\n",
        "\n",
        "    output = [(i, d) for i, d in output if d != 100]\n",
        "\n",
        "    if any(i == 19 for i, d in output):\n",
        "        print(\"Вершина 19 достигнута!\")\n",
        "        break\n",
        "\n",
        "for i, M in graph_struct:\n",
        "    if M.id == 19:\n",
        "        print(f\"Кратчайший путь от вершины 0 до вершины 19: {M.distance}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDPzZKVVYfOm",
        "outputId": "df646780-8a5f-4110-caae-43863b35509b"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Итерация 1:\n",
            "Обновленные вершины: [1, 3]\n",
            "Итерация 2:\n",
            "Обновленные вершины: [2, 4, 8]\n",
            "Итерация 3:\n",
            "Обновленные вершины: [5, 6, 10, 11, 7, 9]\n",
            "Итерация 4:\n",
            "Обновленные вершины: [16, 13, 12]\n",
            "Итерация 5:\n",
            "Обновленные вершины: [15, 17, 14]\n",
            "Итерация 6:\n",
            "Обновленные вершины: [18]\n",
            "Итерация 7:\n",
            "Обновленные вершины: [19]\n",
            "Вершина 19 достигнута!\n",
            "Кратчайший путь от вершины 0 до вершины 19: 7\n"
          ]
        }
      ]
    }
  ]
}